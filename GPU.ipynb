{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "上から順番に再生ボタンを押して行ってください。下2つは自分のbotの設定を入れてください。"
      ],
      "metadata": {
        "id": "f5IcFbdI0RGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk8Tsu5nogRL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = \"elyza/ELYZA-japanese-Llama-2-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16,device_map=\"auto\")"
      ],
      "metadata": {
        "id": "Iq3d6PiJoqV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genText(text):\n",
        "  with torch.no_grad():\n",
        "    token_ids = tokenizer.encode(text,add_special_tokens=False,return_tensors=\"pt\")\n",
        "    output_ids = model.generate(token_ids.to(model.device),max_new_tokens=50,pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id,)\n",
        "  return tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "J5kQPD5io3nj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import time\n",
        "import urllib"
      ],
      "metadata": {
        "id": "FD0F-MkrvTXZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(text):\n",
        "  setting = \"あなたはかわいらしい口調で話すaobakuntstsという名前のアシスタントです。\"#@param {type:\"string\"}\n",
        "  return genText(\"<s>[INST] <<SYS>>\\n\"+ setting +\"\\n<</SYS>>\\n\\n\" + text +\" [/INST] \").replace(\"\\n\",\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Mclg5THOpmJv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = json.loads(requests.get(\"https://aobakun_themovie.onrender.com/bbs/bot\").text)\n",
        "n = t[0]\n",
        "seed = \"\\u3053\\u3053\\u306Bbot\\u306E\\u30B7\\u30FC\\u30C9\\u3092\\u5165\\u529B\"#@param {type:\"string\"}\n",
        "name = \"\\u3060\\u3044\\u3075\\u304F\"#@param {type:\"string\"}\n",
        "while True:\n",
        "  t = json.loads(requests.get(\"https://yukibbs-server.onrender.com/bbs/bot\").text)\n",
        "  if n == t[0] or t[1][0] != \":\":\n",
        "   time.sleep(1)\n",
        "   continue\n",
        "  n = t[0]\n",
        "  requests.get(fr\"https://aobakun_themovie.onrender.com/bbs/result?name={urllib.parse.quote(name)}&message={n}+{urllib.parse.quote(chat(t[1][1:]))}:&seed={urllib.parse.quote(seed)}&channel=main\",cookies={\"yuki\":\"True\"})"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NzXlkAqvLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
